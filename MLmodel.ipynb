{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import scipy.io\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('/home/dev/Letöltések/mpii_dataset.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63484/934581437.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(['Category','Activity'],1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df.drop(['Category','Activity'],1)\n",
    "df = df.sample(n = len(df)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63484/1936806666.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_df= test_df.append(transferdata_df)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NAME</th>\n",
       "      <th>r ankle_X</th>\n",
       "      <th>r ankle_Y</th>\n",
       "      <th>r knee_X</th>\n",
       "      <th>r knee_Y</th>\n",
       "      <th>r hip_X</th>\n",
       "      <th>r hip_Y</th>\n",
       "      <th>l hip_X</th>\n",
       "      <th>l hip_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>r shoulder_Y</th>\n",
       "      <th>l shoulder_X</th>\n",
       "      <th>l shoulder_Y</th>\n",
       "      <th>l elbow_X</th>\n",
       "      <th>l elbow_Y</th>\n",
       "      <th>l wrist_X</th>\n",
       "      <th>l wrist_Y</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>066668565.jpg</td>\n",
       "      <td>748</td>\n",
       "      <td>549</td>\n",
       "      <td>664</td>\n",
       "      <td>471</td>\n",
       "      <td>738</td>\n",
       "      <td>366</td>\n",
       "      <td>724</td>\n",
       "      <td>366</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>697</td>\n",
       "      <td>242</td>\n",
       "      <td>683</td>\n",
       "      <td>325</td>\n",
       "      <td>650</td>\n",
       "      <td>290</td>\n",
       "      <td>1.884420</td>\n",
       "      <td>running, marathon</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>046484980.jpg</td>\n",
       "      <td>1025</td>\n",
       "      <td>947</td>\n",
       "      <td>770</td>\n",
       "      <td>634</td>\n",
       "      <td>1037</td>\n",
       "      <td>584</td>\n",
       "      <td>1220</td>\n",
       "      <td>581</td>\n",
       "      <td>...</td>\n",
       "      <td>265</td>\n",
       "      <td>1260</td>\n",
       "      <td>243</td>\n",
       "      <td>1245</td>\n",
       "      <td>569</td>\n",
       "      <td>1146</td>\n",
       "      <td>733</td>\n",
       "      <td>7.170018</td>\n",
       "      <td>sitting, arts and crafts,  carving wood, weavi...</td>\n",
       "      <td>miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>053304329.jpg</td>\n",
       "      <td>879</td>\n",
       "      <td>714</td>\n",
       "      <td>864</td>\n",
       "      <td>642</td>\n",
       "      <td>849</td>\n",
       "      <td>545</td>\n",
       "      <td>880</td>\n",
       "      <td>546</td>\n",
       "      <td>...</td>\n",
       "      <td>413</td>\n",
       "      <td>846</td>\n",
       "      <td>405</td>\n",
       "      <td>809</td>\n",
       "      <td>370</td>\n",
       "      <td>817</td>\n",
       "      <td>337</td>\n",
       "      <td>1.512762</td>\n",
       "      <td>standing quietly, standing in a line</td>\n",
       "      <td>inactivity quiet/light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>070662987.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>393</td>\n",
       "      <td>391</td>\n",
       "      <td>399</td>\n",
       "      <td>248</td>\n",
       "      <td>350</td>\n",
       "      <td>269</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>246</td>\n",
       "      <td>147</td>\n",
       "      <td>236</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>211</td>\n",
       "      <td>2.681564</td>\n",
       "      <td>fishing from river bank</td>\n",
       "      <td>fishing and hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>090408171.jpg</td>\n",
       "      <td>400</td>\n",
       "      <td>425</td>\n",
       "      <td>400</td>\n",
       "      <td>357</td>\n",
       "      <td>392</td>\n",
       "      <td>283</td>\n",
       "      <td>426</td>\n",
       "      <td>282</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>438</td>\n",
       "      <td>202</td>\n",
       "      <td>448</td>\n",
       "      <td>232</td>\n",
       "      <td>452</td>\n",
       "      <td>261</td>\n",
       "      <td>1.358705</td>\n",
       "      <td>ballet, modern, or jazz</td>\n",
       "      <td>dancing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           NAME  r ankle_X  r ankle_Y  r knee_X  r knee_Y  \\\n",
       "0           0  066668565.jpg        748        549       664       471   \n",
       "1           0  046484980.jpg       1025        947       770       634   \n",
       "2           0  053304329.jpg        879        714       864       642   \n",
       "3           0  070662987.jpg         -1         -1       393       391   \n",
       "4           0  090408171.jpg        400        425       400       357   \n",
       "\n",
       "   r hip_X  r hip_Y  l hip_X  l hip_Y  ...  r shoulder_Y  l shoulder_X  \\\n",
       "0      738      366      724      366  ...           235           697   \n",
       "1     1037      584     1220      581  ...           265          1260   \n",
       "2      849      545      880      546  ...           413           846   \n",
       "3      399      248      350      269  ...            97           246   \n",
       "4      392      283      426      282  ...           198           438   \n",
       "\n",
       "   l shoulder_Y  l elbow_X  l elbow_Y  l wrist_X  l wrist_Y     Scale  \\\n",
       "0           242        683        325        650        290  1.884420   \n",
       "1           243       1245        569       1146        733  7.170018   \n",
       "2           405        809        370        817        337  1.512762   \n",
       "3           147        236        217        218        211  2.681564   \n",
       "4           202        448        232        452        261  1.358705   \n",
       "\n",
       "                                            Activity                Category  \n",
       "0                                  running, marathon                 running  \n",
       "1  sitting, arts and crafts,  carving wood, weavi...           miscellaneous  \n",
       "2               standing quietly, standing in a line  inactivity quiet/light  \n",
       "3                            fishing from river bank     fishing and hunting  \n",
       "4                            ballet, modern, or jazz                 dancing  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transferdata_df = df.iloc[- 1400:, 0:]\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df= test_df.append(transferdata_df)\n",
    "train_df =df.drop(transferdata_df.index)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_loc=(\"/run/media/dev/Windows_7_Ultimate_32_Bit/Images/images/\")\n",
    "#imgArray = np.array([])\n",
    "#files = glob.glob(img_loc+'*.jpg')\n",
    "imgcomb=[]\n",
    "\n",
    "\n",
    "images=[]       \n",
    "trainimglabels=train_df.loc[:,'r ankle_X':'Scale']\n",
    "trainfilenames=train_df['NAME']\n",
    "\n",
    "testimglabels=test_df.loc[:,'r ankle_X':'Scale']\n",
    "testfilenames=test_df['NAME']\n",
    "\n",
    "class Imagedataset(Dataset):\n",
    "    def __init__(self,fnames,labels,transform=None):\n",
    "        self.fnames=fnames\n",
    "        self.labels=labels\n",
    "        self.transform=transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def NormaliseData(self,img,idx):\n",
    "        #print(self.labels.head())\n",
    "        height, width = img.shape\n",
    "        #print(self.labels.head())\n",
    "        Xcoord=[]\n",
    "        Ycoord=[]\n",
    "        x=0\n",
    "        for i in range(0,31,2):\n",
    "            self.labels.iloc[idx,i]=(self.labels.iloc[idx,i]*(256/width))\n",
    "            Xcoord.append(self.labels.iloc[idx,i])\n",
    "            self.labels.iloc[idx,i+1]=(self.labels.iloc[idx,i+1]*(256/height))\n",
    "            Ycoord.append(self.labels.iloc[idx,i+1])\n",
    "            x=x+1\n",
    "        X_min=np.min(Xcoord)\n",
    "        Y_min=np.min(Ycoord)\n",
    "        X_max=np.max(Xcoord)\n",
    "        Y_max=np.max(Ycoord)\n",
    "        x=0\n",
    "        for i in range(0,31,2):\n",
    "            self.labels.iloc[idx, i] = (self.labels.iloc[idx, i] - X_min) / (X_max - X_min)\n",
    "            self.labels.iloc[idx, i+1] = (self.labels.iloc[idx, i+1] - Y_min) / (Y_max - Y_min)\n",
    "            x=x+1\n",
    "        #print(self.labels.head())\n",
    "        normImg=cv2.resize(img,(256,256))\n",
    "        return normImg\n",
    "\n",
    "\n",
    "    def __getitem__ (self, idx):\n",
    "        Rimg=cv2.imread(img_loc+self.fnames[idx])\n",
    "        Gimg=cv2.cvtColor(Rimg,cv2.COLOR_BGR2GRAY)\n",
    "        Gimg=self.NormaliseData(Gimg,idx)\n",
    "        #for i in range(0,31,2):\n",
    "         #   y=self.labels.iloc[idx,i+1]\n",
    "          #  x=self.labels.iloc[idx,i]\n",
    "           # cv2.circle(Gimg,(int(x),int(y)),5,(0,255,0),-1)\n",
    "        #cv2.imshow(\"gay\", Gimg)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        Gimg = Gimg.astype(np.float32) / 255.\n",
    "        if self.transform:\n",
    "            Gimg = self.transform(Gimg)\n",
    "       \n",
    "        helper=self.labels.iloc[idx, :-1]\n",
    "       \n",
    "        target=helper.values\n",
    "        target=target.reshape(-1,2)\n",
    "     \n",
    "        return (Gimg,target)\n",
    "\n",
    "    \n",
    "train_dataset= Imagedataset(trainfilenames,trainimglabels)\n",
    "test_dataset= Imagedataset(testfilenames,testimglabels)\n",
    "\n",
    "train_loader=DataLoader(train_dataset,batch_size=15, shuffle=True, num_workers=4)\n",
    "test_loader=DataLoader(test_dataset,batch_size=15, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "data, target= train_dataset.__getitem__(1)\n",
    "asdf=pd.DataFrame(data)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.fnames.iloc[4]\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc1 = nn.Linear(256*16*16,1024)\n",
    "        self.fc2 = nn.Linear(1024,512)\n",
    "        self.fc3 = nn.Linear(512,128)\n",
    "        self.fc4 = nn.Linear(128,16*2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.conv1(X)\n",
    "        X = F.relu(X)\n",
    "        X = F.max_pool2d(X,kernel_size=2,stride=2)\n",
    "        X = self.conv2(X)\n",
    "        X = F.relu(X)\n",
    "        X = F.max_pool2d(X,kernel_size=2,stride=2)\n",
    "        X = self.conv3(X)\n",
    "        X = F.relu(X)\n",
    "        X = F.max_pool2d(X,kernel_size=2,stride=2)\n",
    "        X = self.conv4(X)\n",
    "        X = F.relu(X)\n",
    "     \n",
    "        X = F.max_pool2d(X,kernel_size=2,stride=2)\n",
    "        X = torch.flatten(X,1)\n",
    "        X = self.fc1(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.fc2(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.fc3(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.fc4(X)\n",
    "        X=X.view(-1,16,2)\n",
    "        output = F.log_softmax(X, dim=1)\n",
    "        return output\n",
    "    \n",
    "torch.manual_seed(101)\n",
    "model = ConvolutionalNetwork().to(dev)\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.BCEWithLogitsLoss() #try diceloss, MultiLabelSoftMarginLoss\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dev, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  \n",
    "  for batch_idx in range(0,len(train_loader),15):\n",
    "    #print(\"dik\")\n",
    "    #start_idx = batch_idx\n",
    "    #end_idx = min(len(train_loader), batch_idx + 20)\n",
    "    batch=list(itertools.islice(train_loader,15))\n",
    "    for data, target in batch:\n",
    "      #print(\"coc\")\n",
    "      data=data.unsqueeze(1)\n",
    "      #print(data.shape ,\" MIAGECI \",target.shape)\n",
    "      data, target = data.to(dev), target.to(dev)\n",
    "      optimizer.zero_grad()\n",
    "      output = model(data)\n",
    "      loss = criterion(output, target)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.3f}'.format(\n",
    "      epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "      100. * batch_idx / len(train_loader), loss.item()))   \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.52156866, 0.53333336, 0.53333336, ..., 0.7019608 , 0.69803923,\n",
       "         0.69803923],\n",
       "        [0.52156866, 0.53333336, 0.53333336, ..., 0.7019608 , 0.69411767,\n",
       "         0.6901961 ],\n",
       "        [0.52156866, 0.53333336, 0.53333336, ..., 0.7019608 , 0.6901961 ,\n",
       "         0.6862745 ],\n",
       "        ...,\n",
       "        [0.22352941, 0.18039216, 0.17254902, ..., 0.42352942, 0.42745098,\n",
       "         0.45490196],\n",
       "        [0.24705882, 0.18039216, 0.17254902, ..., 0.43137255, 0.43529412,\n",
       "         0.45490196],\n",
       "        [0.22745098, 0.18431373, 0.17254902, ..., 0.43137255, 0.43529412,\n",
       "         0.45490196]], dtype=float32),\n",
       " array([[0.33516628, 0.92309837],\n",
       "        [0.33516628, 0.69775871],\n",
       "        [0.33516628, 0.45990018],\n",
       "        [0.85444469, 0.45990018],\n",
       "        [0.91738753, 0.72279645],\n",
       "        [0.92918931, 1.        ],\n",
       "        [0.59480548, 0.45990018],\n",
       "        [0.42564661, 0.10937182],\n",
       "        [0.48937191, 0.12574633],\n",
       "        [0.        , 0.        ],\n",
       "        [0.39024126, 0.38299855],\n",
       "        [0.14633777, 0.32755784],\n",
       "        [0.09126279, 0.15408207],\n",
       "        [0.75609651, 0.06466157],\n",
       "        [1.        , 0.21667642],\n",
       "        [0.8701804 , 0.36153763]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_dataset.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 1804979.401\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 1733464.101\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 1533093.711\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 1355121.247\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 1257885.471\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 1134656.349\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 1057270.157\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 1016185.965\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 891320.151\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 784170.314\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 698220.308\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 674644.896\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 580601.354\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 547313.799\n",
      "Train Epoch: 1 [0/15972 (0%)]\tLoss: 547803.029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m6\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train(model, dev, train_loader, optimizer, epoch)\n",
      "Cell \u001b[0;32mIn [40], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dev, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(train_loader),\u001b[39m15\u001b[39m):\n\u001b[1;32m      5\u001b[0m   \u001b[39m#print(\"dik\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m   \u001b[39m#start_idx = batch_idx\u001b[39;00m\n\u001b[1;32m      7\u001b[0m   \u001b[39m#end_idx = min(len(train_loader), batch_idx + 20)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m   batch\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(train_loader,\u001b[39m15\u001b[39;49m))\n\u001b[1;32m      9\u001b[0m   \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m     10\u001b[0m     \u001b[39m#print(\"coc\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     data\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    train(model, dev, train_loader, optimizer, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
